\documentclass[a4paper, 13pt]{scrreprt}
\usepackage[utf8]{inputenc} 
\usepackage{amssymb}
\usepackage[ngerman]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{pstricks}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage[pdfborder={0 0 0}]{hyperref}

\pagestyle{headings}

\newtheorem{satz}{Satz}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollar}[theorem]{Corollar}
\theoremstyle{definition} \newtheorem{definition}{Definition}[section]

\newenvironment{beweis}[1][Beweis]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{beispiel}[1][Beispiel]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{bemerkung}[1][Bemerkung]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\RR}{\mathbb{R}}

\begin{document}
\title{Nichtlineare Dynamik}
\publishers{\small{Fehler in der Mitschrift an
\url{alexander.book@gmx.de}} oder 
\url{dominik.o@gmx.net}}
\maketitle
\tableofcontents


\chapter{Grundlagen}
\section{Dynamische Systeme}
\begin{definition}[dynamische Systeme]
Wir behandeln zwei Arten von dynamischen Systemen:
\begin{enumerate}
\item \emph{kontinuierliches dynamisches System}: Es gibt eine kontinulierliche Zeitvariable $t\in\mathbb{R}$
\item \emph{diskretes dynamisches System}: Es gibt eine kontinulierliche Zeitvariable $t\in\mathbb{Z}$
\end{enumerate}
Im folgenden bezeichnet $T$ entweder $\mathbb{R}$ oder $\mathbb{Z}$, je nachdem, welches dynamische System im Kontext verwendet wird.

Es gibt einen \emph{(Zustands-)Phasenraum} $X$, der den Zustand eines Systems mit verschiedenen Gr"o"sen beschreibt $(X\subseteq \mathbb{R}^n, n\in \mathbb{N})$. $x\in X$ beschreibt somit einen m"oglichen Zustand eines \emph{dynamischen Systems}. Falls $\operatorname{dim}(X) < \infty$, so nennt man es \emph{endlich dimensionales dynamisches System}. Andernfalls ($\operatorname{dim}(X) = \infty$) nennt man es \emph{unendlich dimensionales dynamisches System}. Mit \emph{Dynamik} bezeichnet man die zeitliche Ver"anderung des Zustands eines dynamischen Systems.
\end{definition}


Generell beginnt ein dynamisches System bei einer Anfangszeit $t_o$ und einem Zustand $x(t_0) = x_0 \in X$. Anhand dieses Punktes wird jedem andern Zeitpunkt ein eindeutiger Zustand zugewiesen ($x(t_0) = x_0 \Rightarrow \forall t\in T\  \exists! x_t\in\mathbb{R}^n: x(t) = x_t$)
Diese Zuordnung wird durch die \emph{Flussabbildung} definiert:
$$\phi\colon \mathbb{R}\times X\to X, \ \forall t \in T: x(t):= \phi(t-t_0, x_0) $$


\begin{definition}[Klassifikation von dynamischen Systemen]
Man unterscheidet dynamische Systeme in lineare und nicht-lineare Systeme:
\begin{enumerate}
\item \emph{Lineares dynamisches System}: $\phi(t, \cdot)\colon X \to X$ ist linear. Man schreibt dann auch $\phi(t, x) = \phi(t)x$. Dabei ist $\phi(t)$ ein linearer Operator f"ur alle $t\in T$
\item \emph{Nichtlineares dynamisches System}: $\phi(t, \cdot)\colon X \to X$ ist nicht linear.
\end{enumerate}
\end{definition}
\begin{definition}[Phasendiagramm]
Durch ein dynamischen Systems $(X,\phi)$ wird jedem Zustand $x\in X$ ein \emph{Orbit} zugeordnet:
$$\Gamma_x := \left \{\left. y \in X \right | \exists t\in T: \phi(t,x) = y\right \}$$ 
Ein \emph{Phasendiagramm} ist die Skizze des Orbits $\Gamma_x$ f"ur einige $x \in X$.
\begin{description}
\item[Bemerkung]Durch jeden Punkt $x\in X$ verl"auft genau ein Orbit $\Gamma_x$. Insbesondere k"onnen sich Orbits nicht traversal (selbst) schneiden.
\end{description}
\end{definition}
\subsection{Eigenschaften der Flussabbildung $\phi$}
Die Flussabbildung gen"ugt folgenden Eigenschaften:
\begin{enumerate}
\item $\forall x\in X: \phi(0,x) = x$
\item $\phi(\cdot, x)$ ist stetig f"ur alle $x\in X$.
\item $\phi(t, \cdot)$ ist stetig f"ur alle $t\in T$.
\item $\phi(t, \cdot)\colon X \to X$ ist ein Hom"oomorphismus (d.h. bijektiv und Umkehrabbildung ist stetig)
\item $\phi(s+t, x) = \phi\left(s, \phi(t,x)\right)$ f"ur alle $s,t \in T,\  x\in X$
\end{enumerate}

\section{Elementarste Typen von dynamischen Systemen}
Dynamische Systeme k"onnen auch implizit angegeben werden. Im Folgenden werden die zwei wichtigsten dynamischen Systeme f"ur diese Vorlesung vorgestellt.
\subsection{Gew"ohnliche Differentialgleichungs Systeme (GDG-Systeme)}
GDG-Systeme sind ein Beispiel f"ur kontinuierliche dynamische Systeme. Betrachtet man eine autonome gew"ohnliche Differentialgleichung 1. Ordnung
$$\dot x= v(x)$$
wobei $v\colon\mathbb{R}^n\to\mathbb{R}^n$ ein Vektorfeld ist. Durch das zugeh"orige AWP $x(0) = x_0$ wird die L"osung $x(t) = \phi(t, x_0)$ festgelegt, falls $v$ hinreichende Struktur besitzt. Falls $v$ beispielsweise lokal Lipschitz-stetig ist, liefert Picard-Lindel"of eine lokal eindeutige L"osung. 
Dies induziert ein dynamisches System $(X, \phi)$, wobei $X = \mathbb{R}^n$, bzw. $X$ das Definitionsgebiet des Vektorfeldes ist.
\begin{lemma}
Die durch dieses AWP induziert $\phi$ gen"ugt den Eigenschaften einer Flussabbildung
\end{lemma}
\begin{beweis}
Sei $\phi(t, x)$ die \emph{Fundamentall"osung} der Differentialgleichung
$$\dot x = v(x)$$
wobei $v\in C^1(\mathbb{R}^n)$. D.h. $x(t) = \phi(t,x)$ ist die eindeutige L"osung des zugeh"origen AWP $x(0) = x_0$.
Folglich ist $\phi(t+s, x)$ eine L"osung der Differentialgleichung f"ur alle $s\in \mathbb{R}$, denn:
$$\frac{\mathrm d}{\mathrm dt} \phi(t+s, x_0) = v\bigl(\phi(t+s, x_0)\bigr)$$
Aber $\left . \phi(t+s, x_0) \right |_{t=0} = \phi(s, x_0)$ ist die Anfangsbedingung dieser L"osung. Also l"ost $\phi(t+s, x_0)$ das AWP $x(0) = \phi(s, x_0)$.
Deswegen gilt $\phi(t+s, x_0) = \phi\left(t, (\phi(s, x_0)\right)$
\end{beweis}

\subsection{Hom"oomorphismus Systeme (Hom-Systeme)}
Betrachte einen Hom"oomorphismus $\psi\colon X \to X$. Dieser induziert ein diskretes dynamisches System wie folgt:
\begin{align*}
\phi(k, x) := \begin{cases}
\psi^k(x), &\mbox{ falls } k \in \mathbb{N} \\
\psi^0(x) = x,& \mbox{ falls } k = 0 \\
\psi^{-k}(x) := (\psi^{-1})^{-k}(x), &\mbox{ falls } k \in \mathbb{Z}\setminus\mathbb{N}_0
\end{cases}
\end{align*}
$\phi$ ist damit die Flussabbildung eines diskreten dynamischen Systems $(X, \phi)$.
\section{Gleichgewichtspunkte}
\begin{definition}
Ein Punkt $x_G \in X$ hei"st \emph{Gleichgewichtszustand(-punkt)} des dynamischen Systems $(X,\phi)$, falls gilt
$$ \forall t \in T: \phi(t, x_G) = x_G$$
\end{definition}

\subsection{Gleichgewichtspunkte in GDG-Systemen}
Sei $x_G$ ein Gleichgewichtspunkt des durch die Differentialgleichung $\dot x = v(x)$ induzierte dynamischen Systems. Dann gilt:
$$ \forall t\in \mathbb{R}: \phi(t, x_G) = x_G $$
Differenzieren liefert 
$$ \frac{\mathrm d}{\mathrm dt} \phi(t, x_G) = 0 $$
Somit liegt jeder Gleichgewichtspunkt des dynamischen Systems in der Nullstellenmenge des Vektorfeldes $v$.
$$ x_G \mbox{ Gleichgewichtspunkt } \Leftrightarrow x_G \in v^{-1}(\{0\}) $$

\subsection{Gleichgewichtspunkte in Hom-Systemen}
Sei $\psi$ ein Hom"oomorphismus. Sei $(X, \phi)$ das durch $\psi$ induzierte dynamische System. Somit muss f"ur jeden Gleichgewichtspunkt $x_G$ des dynamischen Systems gelten:
$$ \forall k\in\mathbb{Z}: \phi(k, x_G) = \psi^k(x_G) = x_G$$
F"ur $k=1$ folgt $x_G= \psi(x_G)$. Also sind alle Gleichgewichtspunkte des dynamischen Systems Fixpunkte von $\psi$. 
$$ x_G \mbox{ Gleichgewichtspunkt } \Leftrightarrow x_G \mbox{ Fixpunkt von } \psi $$

\subsection{Gleichgewichtspunkte von linearen dynamischen Systemen}
Im linearen Fall ist f"ur beide Typen GDG- bzw. Hom-Systeme ein trivialer Gleichgewichtspunkt $x_G = 0$ gegeben.
\begin{enumerate}
\item GDG-System: Gegeben sei die Differentialgleichung $$\dot x = v(x) = Ax, \ A \in \mathbb{R}^{n\times n}, \ x\in \mathbb{R}^n$$
Dann ist die Flussabbildung gegeben durch $\phi(t, x) = \exp{(tA)}x$. Zur Wiederholung: Die exponential Matrix ist definiert durch 
$\exp{(A)} = \sum_{k=0}^{\infty} \frac{A^k}{k!}$ und konvergiert f"ur jedes $A\in\mathbb{R}^{n\times n}$ gleichm"a"sig.

Die Bedingung ein Gleichgewichtspunkt zu sein ist $\phi(t, x) = 0$. Also erf"ullt $x_G = 0$ trivialer weise dieser Bedingung.

\item Hom-System: Sei $\psi$ eine lineare Funktion, also 
$$\psi( x) = Ax, \ A\in\mathbb{R}^{n \times }, \ x\in \mathbb{R}^n$$
Damit $\psi$ ein Hom"oomorphismus wird, muss $\det{(A)} \not = 0$ gelten. Die Bedingung f"ur ein Gleichgewichtspunkt ist diesesmal 
$$ \psi(x) = x $$
$x_G = 0$ erf"ullt dies Bedingung und ist daher ein Gleichgewichtspunkt.

\end{enumerate}

\subsection{Beispiele von Gleichgewichtspunkten}
\begin{beispiel}[Gleichgewichtspunkte des DGD-Systems]
Betrachte die Differentialgleichung $\dot x = x - x^3 = v(x), \ x \in \mathbb{R} = X$
Die Gleichgewichtspunkte sind also gegeben durch 
\begin{align*}
v(x) &= x - x^3 = 0 \\
& = x(1-x^2) = 0\\
\Rightarrow x_G^1 = 0, x_G^{2/3} = \pm 1
\end{align*}
\end{beispiel}

\begin{beispiel}[Gleichgewichtspunkte des Hom-Systems]
Betrachten den Hom"oomorphismus $\psi(x) = x^3,\ x\in \mathbb{R}$. Die Gleichgewichtspunkte des von $\psi$ induzierten dynamischen Systems sind gegeben durch
\begin{align*}
\psi(x) = x \Leftrightarrow x^3 = x &\Leftrightarrow x^3- x = 0\\
& x_G^1 = 0, x_G^{2/3} = \pm 1
\end{align*}

\end{beispiel}

\section{Dynamische Stabilit"at von Gleichgewichtspunkten im Sinne von Lyapunov}
Sei $(X, \phi)$ ein dynamisches System, $x_G\in X$ ein Gleichgewichtspunkt, $(X, d)$ ein metrischer Raum.

Wiederholung: $d$ hei"st Metrik auf $X$, falls $d\colon X \times X \to \mathbb{R}$ und f"ur beliebige Elemente $x, y, z\in X$ gilt:
\begin{enumerate}
\item $d(x,y) \geq 0, \ d(x, y) = 0 \Leftrightarrow x = y$ (Definitheit)
\item $d(x,y) = d(y, x)$ (Symmetrie)
\item $d(x, y) \leq d(x,z) + d(z, y) $ (Dreiecksungleichung)
\end{enumerate}

\begin{definition}
Ein Gleichgewichtspunkt $x_G$ hei"st
\begin{itemize}
\item \emph{stabil (im Sinne von Lyapunov)}, falls 
$$ \forall \varepsilon > 0 \ \exists \delta > 0 \ \forall x \in X, t \in T, t > 0: d(x, x_G) < \delta \Rightarrow d\left(\phi(t, x), x_G\right) < \varepsilon$$
\item \emph{instabil (im Sinne von Lyapunov)}, falls $x_G$ nicht stabil ist.
\item \emph{asymptotisch stabil (im Sinne von Lyapunov)}, falls $x_G$ stabil ist und gilt
$$ \exists b > 0\ \forall x \in X: d(x, x_G) < b \Rightarrow \lim_{t\to\infty}{d\left(\phi(t, x), x_G\right)} = 0$$
\end{itemize}
\end{definition}
\begin{figure}[htpb]
\centering
\includegraphics[width=0.45\textwidth]{img/stabilitaet/stabilitaet_lypunov.pdf}
\includegraphics[width=0.45\textwidth]{img/stabilitaet/instabilitaet_lypunov.pdf}
\caption{Stabilität(links); Instabilität (rechts)}
\end{figure}

\subsection{Indirekte Methode von Lyapunov}
\subsubsection{Indirekte Methode von Lyapunov f"ur GDG-Systeme}
Sei $v$ ein $C^1$-Vektorfeld ($v\in C^1(\mathbb{R}^n, \mathbb{R}^n)$), $x_G$ ein Gleichgewichtspunkt des von $v$ erzeugten GDG-Systems. Es bezeichne $\sigma(A)$ die Menge aller Eigenwerte der Matrix $A$.
\begin{lemma}
Betrachte die Jacobi-Matrix $J_v(x)$ an der Stelle $x = x_G$.
\begin{itemize}
\item Falls $\forall \lambda \in \sigma(J_v(x_G)): \operatorname{Re} \lambda < 0$, dann ist $x_G$ asymptotisch stabil.
\item Falls $\exists \lambda \in \sigma(J_v(x_G)): \operatorname{Re} \lambda > 0$, dann ist $x_G$ instabil.
\item Falls $v$ ein lineares dynamisches System induziert und es gilt 
$$ \forall \lambda \in \sigma(J_v(x_G)): \operatorname{Re} \leq 0 \mbox { und } \lambda \mbox{ halb einfach, falls } \operatorname{Re} \lambda = 0$$
dann ist $x_G$ stabil. Dabei ist ein Eigenwert $\lambda$ \emph{halb einfach}, falls seine geometrische Vielfachheit, seiner algebraischen Vielfachheit entspricht.
\end{itemize}
\end{lemma}
\subsubsection{Indirekt Methode von Lyapunov f"ur Hom-Systeme}
Sei $\psi $ ein $C^1$-Hom"oomorphismus ($C^1$-Diffeomorphismus), $x_G$ ein Gleichgewichtspunkt des von $\psi$ erzeugten Hom-Systems.
\begin{lemma}
Betrachte die Jacobi-Matrix von $\psi$ an der Stelle $x_G$
\begin{itemize}
\item Falls $\forall \lambda \in \sigma(J_\psi(x_G)): |\lambda| < 1$, dann ist $x_G$ asymptotisch stabil
\item Falls $\exists \lambda \in \sigma(J_\psi(x_G)): |\lambda| > 1$, dann ist $x_G$ instabil.
\item Falls $\psi$ ein lineares dynamisches System erzeugt und gilt 
$$\forall \lambda \in \sigma(J_\psi(x_G)): |\lambda| \leq 1 \mbox{ und } \lambda \mbox{ halbeinfach, falls } |\lambda| = 1$$
dann ist $x_G$ stabil.
\end{itemize}
\end{lemma}
\subsection{Direkte Methode von Lyapunov}
\subsubsection{Direkte Methode von Lyapunov f"ur GDG-Systeme}
Sei $v$ ein $C^1$-Vektorfeld, $x_G$ ein Gleichgewichtspunkt.
\begin{definition}
Eine \emph{(strikte) Lyapunov-Funktion} $V$ ist eine Funktion $V \in C^1(U, \mathbb{R})$, sodass $x_G \in U, \ U\subset \mathbb{R}^n$ offen und 
\begin{enumerate}
\item $V(x_G) = 0$
\item $\forall x \in U\setminus \{x_G\}: V(x) > 0$
\item $\forall x \in U: \langle \nabla V(x), v(x) \rangle \stackrel{(<)}\leq 0$ \\
				\(( \Rightarrow \partial_t V(\phi(t,x)) = \langle \nabla V(\phi(t,x)), v(\phi(t,x)) \rangle \stackrel{(<)}\leq 0 )\)
\end{enumerate}
\end{definition}

\begin{lemma}
Falls eine Lyapunov-Funktion f"ur $v$ um $x_G$ existiert dann ist $x_G$ stabil. Gilt strikte Ungleichheit in $(3)$, dann ist $x_G$ sogar asymptotisch stabil.
\end{lemma}

\begin{description}
\item[Bemerkung]
Falls \( U = \RR^2 \) und \(V\) eine strikte Lyapunov-Funktion zu \(x_G\), dann ist \(x_G\) global asymptotisch stabil.
\end{description}

\begin{beweis} 
Fall \("\leq" : \) \newline
Sei \(\varepsilon > 0\) hinreichend klein, sodass \(\overline{B_{\varepsilon} (x_G)} \subset U\). Sei \(m\) das Minimum von \(V\) auf \(\partial B_{\varepsilon} (x_G) \). Dies existiert, da \(\partial B_{\varepsilon} (x_G) \) kompakt und \(V\) stetig (Satz von Weierstra"s). Dann folgt mit Bedingung 1), 2) : \(m > 0\). \\
Definiere \( \tilde{U} := \{ x \in B_{\varepsilon} (x_G)\ |\ V(x) < m \} \not= \emptyset \) offen. (\(x_G \in \tilde{U}\) und insbesondere ex. \(\delta > 0 \) mit \(B_{\delta} (x_G) \subset \tilde{U} \), wie auch in jedem anderen Punkt von \(\tilde{U})\). \\
\(x_0 \in \tilde{U} \Rightarrow V(x_0) < m \) und damit \(V(\Phi(t,x_0)) \leq V(x_0) < m \)
\begin{addmargin}[38pt]{0pt}
	\(\Rightarrow \Phi(t,x_0) \notin \partial B_{\varepsilon} (x_G)\  \forall t \geq 0 \) \\
	\(\Rightarrow \Phi(t,x_0) \in B_{\varepsilon} (x_G) \) \\
	\(\Rightarrow x_G  \) ist Lyapunov-stabil
\end {addmargin}
\end{beweis}

\begin{beispiel} \(X = \RR^2\) 
	\[ \begin{cases} \dot{x} = y \\
			\dot{y} = x - x^3 \end {cases} 
	\]
\begin{itemize}
	\item Gleichgewichtspunkte: 
		\[v(x,y) = \left( \begin{array}{c} y \\ x-x^3 \end{array} \right) = \left(\begin{array}{c} 0 \\ 0 \end{array} \right) \]
		\[ \Leftrightarrow y = 0, x = 0 \ \lor x = \pm 1\]
		\[ \Rightarrow x_G^1 = \left(\begin{array}{c} 0 \\ 0 \end{array} \right),\  
			x_G^{2/3} = \left( \begin{array}{c} \pm 1 \\ 0 \end{array} \right ) 
		\]
	\item Konstruktion einer Lyapunov Funktion\\
		\( II \cdot y - I \cdot x \)
		\begin{align*}
			-x\dot{y} + y \dot{y} = -x^3y & = -x^3\dot{x} \\
			\Leftrightarrow \frac {d}{dt} \left( -0,5 x(t)^2 + 0,5 y(t)^2 + 0,25 x(t)^4 \right) & = 0 \\
			\Leftrightarrow -0,5 x(t)^2 + 0,5 y(t)^2 + 0,25 x(t)^4 & = C
		\end{align*}
		Dann ist 
			\[V(x,y) = -0,5 x(t)^2 + 0,5 y(t)^2 + 0,25 x(t)^4 - C\]
		eine Lyapunov-Funktion f"ur jedes \(x_G^i, (i = 1,2,3) \) bei geeigneter Wahl von \(C\), denn
		\begin{itemize}
			\item \(V(x_G^i) = 0 \) mit \( C = 0\) f"ur \( x_G^1\) und \( C = -0,25\) f"ur \(x_G^{2/3}\)
			\item \(\langle \nabla V(x,y), v(x,y) \rangle = 0\)\\
						\(\nabla V(x,y) = \left( \begin{array}{c} -x+x^3 \\ y \end{array} \right) = 
							\left( \begin{array}{c} 0 \\ 0 \end{array} \right) \)
			\item \(HV(x,y) = \left(\begin{array}{cc} -1+3x^2 & 0 \\ 0 & 1 \end{array}\right) \) \\
						\(HV(x_G^1) = \left(\begin{array}{cc} -1 & 0 \\ 0 & 1 \end{array} \right)\) indefinit \(\Rightarrow x_G^1\) ist Sattelpunkt von \(V\) \\
						\(HV(x_G^{2/3}) = \left(\begin{array}{cc} 2 & 0 \\ 0 & 1 \end{array}\right) \) pos. definit \(\Rightarrow x_G^{2/3} \) sind strikte lokale Minima von \(V \Rightarrow V > 0\) f"ur alle \( x \not= x_G^{2/3}\) in einer gewissen Umgebung von \(x_G^{2/3}\).\\
						\(\Rightarrow x_G^{2/3} \) sind Lyapunov-stabil.\\
						\(Jv(x,y) = \left( \begin{array}{cc} 0 & 1 \\ 1-3x^2 & 0 \end{array}\right)
						\Rightarrow Jv(x_G^1) = \left( \begin{array}{cc} 0 & 1 \\ 1 & 0 \end{array}\right) \Rightarrow \lambda_{1/2} = \pm 1 \) \\
						\( \Rightarrow Re(\lambda_{1/2}) > 0 \Rightarrow \) indirekte Methode: \(x_G^1\) ist instabil
			\end{itemize}
	
\end{itemize}
\end{beispiel}

\subsubsection{Direkte Methode f"ur Hom-Systeme} 
Direkte Methode von Lyapunov funktioniert entsprechend des GDG-Falls wobei in der Definition einer Lyapunov-Funktion die Bedingng 3) zu ersetzen ist durch: 
	\[\forall x \in U: V(\Psi(x)) \stackrel{(<)} \leq V(x)\  \]
wobei \(\Psi\) der erzeugende Hom"oomorphismus des Hom-Systems sei.


%-----------------------------------------------------------------------------------------------

\chapter{Lineare Systeme}

\section{GDG-Systeme}
Betrachte die Differentialgleichung
	\[\dot{x} = Ax =: v(x)\]
wobei $x\in\RR^n, A \in \RR^{n\times n}$ \emph{Systemmatrix}
\begin{satz}[Jordannormalform von A]
Es exisitiert eine invertierbare lineare Transformation $T:\RR^n \to \RR^n $, sodass 
$$ J = T ^{-1} A T$$
in Jordan-Normalform ist. Es gilt au"serdem
	\begin{align*}
	& e^{Jt} = e^{T^{-1}AT} = \sum_{j=1}^{\infty} \frac{t^j}{j!} (T^{-1}AT)^j = T^{-1} \sum_{j=1}^{\infty} \frac{t^j}{j!} A^j T = T^{-1} e^{At} T
	\end{align*}
	Dabei ist \(J\) die Matrix der Flu"sabbildung des \emph{J-Systems} \(\dot{\xi} = J\xi\), \(A\) die Matrix des \emph{A-Systems} \(\dot{x} = Ax\)
\end{satz}
	
\begin{description}
\item[Terminologie]
Man sagt, dass das \(J\)- und das \emph{A-System} bez"uglich der linearen Transformation \(T\) zueinander \emph{konjugiert} oder \emph{"aquivalent} sind.
\end{description}

\begin{description}
\item[Bemerkung]
 \(T\) bildet die Orbits des J-Systems bijektiv auf die Orbits des A-Systems ab. Sei dazu \(\xi \in \RR^n\). Dann gilt f"ur die Orbits durch $\xi$
\begin{align*}
	 & e^{Jt} \xi  = T^{-1}e^{At} T \xi \\
	\Leftrightarrow & Te^{Jt} \xi = e^{At}T\xi = e^{At}x
\end{align*}
\(T\) bildet den Orbit durch \(\xi\) des J-Systems  auf den Orbit durch \(x = T\xi\) des A-Systems  ab.
Daher klassifiziert man lineare Differentialgleichungen modulo einer linearen Transformation $T$.

\end{description}


\section{Klassifikation von Phasendiagrammen von GDG-Systemen f"ur $n=1$}
Die erzeugende Differentialgleichung lautet
	\[ \dot{x} = ax, \qquad a \in \RR \]
Man erh"alt dann folgende Klassifikation in Abh"anigkeit von a:
	\begin{enumerate}
		\item $a=0: $ alle Punkte sind Gleichgewichtspunkte
		\item $a > 0: x = 0$ ist eine Quelle
		\item $a > 0: x = 0 $ ist eine Senke
	\end{enumerate}
\section{Klassifikation von Phasendiagrammen von GDG-Systemen f"ur $n=2$}
	\[\dot{x} = Ax, \qquad A \in \RR^{2\times 2} \]
Die Jordannormalform von $A$ kann dann folgende $3$ Typen annehmen
\subsection{Jordannormalform ist in Diagonalform}
\(A\) habe Eigenwerte \(\lambda_1, \lambda_2 \in \RR\) halbeinfach. Die Jordannormalform von $A$ ist gegeben durch $$J = \left(\begin{array}{cc} \lambda_1 & 0 \\ 0 & \lambda_2 \end{array} \right) $$ Das dazugeh"orige Anfangswertproblem lautet dann 
			\[ \begin{cases} \dot{\xi_1} = \lambda_1 \xi_1 , \ \xi_1(0) = \xi_{10}\in\RR \\
				\dot{\xi_2} = \lambda_2 \xi_2 , \ \xi_2(0) = \xi_{20}\in \RR \end {cases} 
			\]
Die L"osung der obigen Differentialgleichung ist offensichtlich 
			\begin{align*}
						\xi_1(t)   = \xi_{10} e^{\lambda_1 t} \\
						\xi_2(t)   = \xi_{20} e^{\lambda_2 t} 
			\end{align*}
Nun wollen wir $\xi_2$ in Abh"anigkeit von $\xi_1$ angeben, falls alle Rechnungen so durchf"uhrbar sind:
					\begin{align*}
						&\frac{\xi_1}{\xi_{10}} = e^{\lambda_1t} \\
						\Leftrightarrow &\ln{\left(\frac{\xi_1}{\xi_{10}}\right)} = \lambda_1 t 		
						\Leftrightarrow t = 	
						\frac {1}{\lambda_1} \ln \left(\frac{\xi_1}{\xi_{10}} \right) \\
						\Rightarrow \xi_2 &  = \xi_{20} \exp\left( \frac{\lambda_2}{\lambda_1} \ln\left(	\frac{\xi_1}{\xi_{10}} \right) \right) = \xi_{20} \left(\frac{\xi_1}{\xi_{10}}\right)^{\frac{\lambda_2}{\lambda_1}}  					
				\end{align*}
Nun k"onnen die Phasendiagramme klassifiziert und skizziert werden. Es ergeben sich daher die F"alle
\subsubsection{1. Fall: \(0<\lambda_1 < \lambda_2\) }
	\( x = 0 \) wird \emph{instabiler Knoten 2. Art} genannt.
\subsubsection{2. Fall: \(\lambda_2 < \lambda_1 < 0\)}
	\( x = 0\) ist wird \emph{stabiler Knoten 2. Art} genannt.
	
	\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.35\textheight]{img/lin_sys/lin_sys_1.pdf}
		\includegraphics[height=0.35\textheight]{img/lin_sys/lin_sys_2.pdf}
		\caption{1. Fall (links); 2. Fall (rechts)}
	\end{figure}	
	
\subsubsection{3. Fall: \( 0 < \lambda_1 = \lambda_2\) }
\( x= 0\) wird \emph{instabiler Knoten 1. Art} genannt.
\subsubsection{4. Fall: $\lambda_1 = \lambda_2 < 0$ }
\( x = 0\) wird \emph{stabiler Knoten 1. Art} genannt.
	\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.20\textheight]{img/lin_sys/lin_sys_3.pdf}
		\includegraphics[height=0.20\textheight]{img/lin_sys/lin_sys_4.pdf}
		\caption{3. Fall (links); 4.Fall (rechts)}
	\end{figure}
\subsubsection{5. Fall: \(\lambda_1 < 0 < \lambda_2\)}
					\(x = 0\) wird \emph{Sattelpunkt} genannt und ist offensichtlich instabil. Es ergeben sich in diesem Fall als Orbits Hyperbeln.
		\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.20\textheight]{img/lin_sys/lin_sys_5.pdf}
		\caption{5. Fall}
	\end{figure}
	
	
	
	
\subsection{Jordannormalform ist in Pseudo-Diagonalform} 
$A$ habe einen geometrisch einfachen und algebraisch doppelten Eigenwert \({\lambda \in \RR}\). Die Jordannormalform von $A$ ist dann gegeben durch
				$$ J = \left( \begin{array}{cc} \lambda & 1 \\ 0 & \lambda \end{array} \right) $$
Das dazuge"orige Anfangswertproblem lautet
				\[\begin{cases} 
					\dot{\xi_1} = \lambda \xi_1 + \xi_2,\  \xi_1(0) = \xi_{10} \in \RR \\
				 	\dot{\xi_2} = \lambda \xi_2, \qquad\  \xi_2(0) = \xi_{20} \in \RR
				\end{cases} \]
Die L"osungen sind schlie"slich folgenderma"sen gegeben

				$$
				\Rightarrow \xi_2(t) = \xi_{20} e ^{\lambda t} \qquad \Rightarrow \xi_1(t) = \xi_{10} e ^{\lambda t} + t \xi_{20} e ^{\lambda t}$$
				Die Orbits sind analog zur vorherigen Jordannormalform darstellbar als
				$$ \xi_1 = \left( \frac{\xi_{10}}{\xi_{20}} + \frac{1}{\lambda} \ln{\frac{\xi_2}{\xi_{20}}}\right) \xi_2$$
solange keine ung"ultige Rechenoperation durchgef"uhrt wird. 
	\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.31\textheight]{img/lin_sys/lin_sys_6.pdf}
		\includegraphics[height=0.31\textheight]{img/lin_sys/lin_sys_6_2.pdf}
		\caption{1. Fall (links); 2.Fall (rechts)}
	\end{figure}
\subsubsection{1. Fall: $\lambda < 0$} 
$x = 0$ wird \emph{stabiler Knoten 3. Art} genannt.
\subsubsection{2. Fall: $\lambda < 0$}
$ x = 0 $ wird \emph{instabiler Knoten 3. Art} genannt.

\subsection{Jordannormalform ist in keiner Diagonalform} 
$A$ habe ein paar komplex konjugierte Eigenwerte $\lambda_{1/2} = \alpha \pm i \beta $. Die reelle Jordannormalform von $A$ ist gegeben durch
				$$ J = \left( \begin{array}{cc} \alpha & \beta \\ - \beta & \alpha \end{array}\right) $$ 
und es ergibt sich das Anfangswertproblem
		\[\begin{cases} 
			\dot{\xi_1} =  \alpha \xi_1 + \beta\xi_2, \ \  \xi_1(0) = \xi_{10} \in \RR \\
			\dot{\xi_2} = -\beta \xi_1 + \alpha \xi_2 , \ \xi_2(0) = \xi_{20} \in \RR
		\end{cases} \]
Die L"osung ist daher		
		\[ \phi(t,\xi_0) = e^{Jt} \xi_0 = e^{(A+B)t} \xi_0 \]
				wobei 
				$$ A = \left( \begin{array}{cc} \alpha & 0 \\ 0 & \alpha \end{array}\right), \ B = \left( \begin{array}{cc} 0 & \beta \\ - \beta & 0 \end{array}\right) $$
Offensichtlich kommutieren $A$ und $B$ miteinander und es gilt $ e^{(A+B)t} = e^{At} e^{Bt} $. Berechnen wir nun die Exponentialmatrix von $A$ bzw. $B$ explizit, so erhalten wir
				$$ e^{At} = e^{\alpha t} \cdot I_2, \  e^{Bt} = \left(\begin{array}{cc} \cos{(\beta t)}  & \sin{(\beta t)} \\ - \sin{(\beta t )} & \cos{(\beta t })  \end{array}\right) \in SO(2) $$
Die explizite L"osung ist dann
				\[\phi(t, \xi_0) = e^{\alpha t} \underbrace{\left(\begin{array}{cc} \cos{(\beta t)}  & \sin{(\beta t)} \\ - \sin{(\beta t )} & \cos{(\beta t })  \end{array}\right)}_{Drehmatrix} \xi_0
				\]
				
\subsubsection{1. Fall: \(\alpha \not = 0\)}
$x=0$ wird \emph{Strudel(Wirbel)} genannt. Falls $\alpha < 0$ so sagt man zus"atzlich, dass $x$ stabil ist. F"ur $\alpha > 0$ entsprechend instabil.
\subsubsection{2. Fall: \(\beta \not = 0\)}
$x=0$ ist \emph{mit den Uhrzeigersinn orientiert}, falls $\beta < 0$. Entsprechend, falls $\beta > 0$ \emph{ gegen den Uhrzeigersinn orientiert}.
\subsubsection{3. Fall: \(\alpha = 0\)}
$x=0$ hei"st \emph{Zentrum}. Dieser ist stabil, jedoch nicht asymptotisch stabil.

\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.25\textheight]{img/lin_sys/lin_sys_7_1.pdf}
		\includegraphics[height=0.25\textheight]{img/lin_sys/lin_sys_7_2.pdf}
		\caption{$\beta < 0 < \alpha$ (links); $\alpha < 0 < \beta$ (rechts)}

		\includegraphics[height=0.25\textheight]{img/lin_sys/lin_sys_7_3.pdf}
		\caption{$\alpha = 0, \beta < 0$}
	\end{figure}
\newpage
\section{Reduktion des Klassifikationsproblems}
\begin{definition}
	Sei \((X,\phi)\) ein dynamisches System. Dann hei"st
	\begin{itemize}
		\item \( M \subset X \) \emph{positiv invariant} \(\Leftrightarrow  \forall t \geq 0: \phi(t,M) \subset M \)
		\item \(\begin{aligned}[t] M \subset X  \text{ \emph{negativ invariant}} 
			& \Leftrightarrow \forall t \leq 0: M \subset \phi(t,M)  \\
			& \Leftrightarrow \forall t \geq 0: \phi(-t,M) \subset M \\
			& \Leftrightarrow \forall t \leq 0: \phi(t,M) \subset M  
			\end{aligned} \)
			
		\item \(\begin{aligned}[t] M \subset X \text{ \emph{invariant}} & \Leftrightarrow M\ \text{positiv und negativ invariant}\\
			& \Leftrightarrow \forall t \in T: \phi(t,M) = M \ 
			\end{aligned} \)
		\end{itemize}	
		Ist \( M \subset X \) invariant, dann bildet 
			\( (M,\left. \phi(t,\cdot)\right|_M) \) ein dynamisches System auf M und wird \emph{Teilsystem} des urspr"unglichen Systems \((X,\phi)\) genannt. 	
\end{definition}

\begin{description}
\item [Bemerkung]
	Jeder invariante Untervektorraum \(U \subset \RR^n \) bzgl. der linearen Abbildung 
		\[x \mapsto Ax : \RR^n \rightarrow \RR^n \]
(d.h. $x\in U\Rightarrow Ax \in U$ ) ist ein invarianter Untervektorraum des GDG-Systems \(\dot{x} = Ax\), denn
		\[\phi(t,x_0) = e^{At} x_0 = \sum_{j=0}^{\infty} \frac{t^j}{j!} \underbrace{A^j x_0}_{\in U}, \qquad x_0 \in U\]
Der Wert der Summe liegt in \(U\), da $U$ abgeschlossen und sie Grenzwert ist von
	\[ e^{At} x_0 = \lim_{N\to \infty} \underbrace{\sum_{j=0}^{N} \frac{t^j}{j!} A^j x_0 }_{\in\  U\ \forall N} \]
\end{description}

\begin{corollar}
	Alle Eigenr"ame \(E_j\) (bzw. verallgemeinerte Eigenr"aume), sowie deren direkte Summen sind kanonisch invariante Unervektorr"aume des Systems
		\[\dot{x} = Ax, \qquad A \in \RR^{n\times n} \]
	\underline{Speziell:} Ist \(\RR^n = \oplus_{j=1}^{N} E_j \) eine direkte Summe von (relativ niedrig dimensionierten) Eigenr"aumen von \(A\), dann ist das urspr"ungliche System \(\dot{x}=Ax\) das direkte Produkt der Teilsysteme auf den \(E_j\).
	Falls sich die Teilsysteme vollst"andig analysieren bzw. klassifizieren lassen, dann auch das urspr"ungliche System \(\dot{x} = Ax\) im \(\RR^n\)
\end{corollar}

\begin{definition}
	Spezielle (verallgemeinerte) Eigenr"aume von \(A\) und damit invariante Untervektorr"aume von \(\dot{x}=Ax\) : 
	\begin{itemize} 
		\item stabiler Unterraum von \(\dot{x}=Ax\)
			$$E^s := \left\{\left. v\in \RR^n \right| (A-\lambda \operatorname{id})(v) = 0 \land \operatorname{Re}(\lambda) < 0\right\}$$ 
			Dies ist der verallgemeinterte Eigenraum zu allen Eigenwerten $\lambda$ von $A$ mit $\operatorname{Re}\lambda < 0$.
		\item instabiler Unterraum von \(\dot{x}=Ax\)
		$$E^u := \left\{\left. v\in \RR^n \right| (A-\lambda \operatorname{id})(v) = 0 \land \operatorname{Re}(\lambda) > 0\right\}$$ 
			Dies ist der verallgemeinterte Eigenraum zu allen Eigenwerten $\lambda$ von $A$ mit $\operatorname{Re}\lambda > 0$.
		\item Zentrums-Unterraum von \(\dot{x}=Ax\)
		$$E^c := \left\{\left. v\in \RR^n \right| (A-\lambda \operatorname{id})(v) = 0 \land \operatorname{Re}(\lambda) = 0\right\}$$ 
			Dies ist der verallgemeinterte Eigenraum zu allen Eigenwerten $\lambda$ von $A$ mit $\operatorname{Re}\lambda = 0$.
	\end{itemize}
\end{definition}
\begin{figure}[htpb]
		\centering
		\includegraphics[height=0.40\textheight]{img/eigenraeume.pdf}
		\caption{$E^c$ entscheidet viel über das Verhalten der Orbits}
\end{figure}

\begin{satz}
Es gilt: 
	\[\RR^n = E^s \oplus E^u \oplus E^c \]
\end{satz}

\begin{description}
	\item[Terminologie]Spezielle Eigenraum-Typen des GDG-Systems $\dot x = Ax$ \\
	\begin{itemize}
		\item \(E^c = \{0\} \Rightarrow x =0\) hei"st hyperbolischer Gleichgewichtspunkt 
		\item \(E^c = \{0\}, {E^s \not= \{0\}, E^u \not= \{0\}} \Rightarrow x =0\) hei"st Sattelpunkt
		\item \(E^c = \{0\}, E^u = \{0\} \Rightarrow x =0\) hei"st Senke (asympt. stabil) 
		\item \(E^c = \{0\}, E^s = \{0\} \Rightarrow x =0\) hei"st Quelle (instabil)
		
	\end{itemize}
\end{description} 

\section{Klassifikation von Phasendiagrammen von Hom-Systemen f"ur $n=1$}

Sei $X = \RR, \ \psi\colon X \to X$ ein linearer Hom"omorphismus, der das lineare dynamische Systeme $(X,\phi)$ erzeugt. Insbesondere ist $\psi(x) = ax$ f"ur ein $a\in\RR\setminus\{0\}$.

Man kann dann die Orbits folgenderma"sen klassifizieren.
\subsubsection{Falls $|a| < 1$}
$x=0$ wird \emph{Senke} genannt und ist stabil.
\subsubsection{Falls $|a| > 1$}
$x=0$ wird \emph{Quelle} genannt und ist instabil.
\subsubsection{Falls $ a < 0$}
$x=0$ wird \emph{orientierungsumkehrend} genannt.
\subsubsection{Falls $a > 0$}
$x=0$ wird \emph{orientierungserhaltend} genannt.
\subsubsection{Falls $|a| = 1$}
$x=0$ wird \emph{Zentrum} genannt. Ist $a = 1$, so ist jeder Punkt $x\in\RR$ ein Gleichgewichtspunkt. F"ur $a=-1$ ergeben sich 2-periodische Orbits (gez"ahlt an der minimalen positiven Periode). Der Punkt \(x = 0\) wird dabei jewweils \emph{Zentrum} genannt.

\begin{figure}[htpb]
		\centering
		\includegraphics[width=1\textwidth]{img/lin_sys/diskret/lin_sys_1.pdf}
		\caption{$|a| < 1, \ a < 0$}

		\includegraphics[width=1\textwidth]{img/lin_sys/diskret/lin_sys_2.pdf}
		\caption{$|a| > 1, \ a > 1$}

		\includegraphics[width=1\textwidth]{img/lin_sys/diskret/lin_sys_3.pdf}
		\caption{$a = -1$}
\end{figure}

\begin{description}
\item[Bemerkung]
	Jeder der bzgl. der linearen Abbildung \(x\mapsto Ax \) invarianter Unterverktorraum \(U\) ist invariant bzgl. des von \(\psi(x) = Ax \) erzeugten dynamische Systems.
\end{description}




\end{document}
